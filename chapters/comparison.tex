%% ==============================
\chapter{Vergleich der Methoden}
\label{ch:Vergleich}
%% ==============================

In \chapref{ch:Dimensionsreduktion} haben wir grundlegende Begriffe geklärt und in
\chapref{ch:MethodenDerDimRed} sechs Methoden der Dimensionsreduktion näher betrachtet. Im jetzigen
Kapitel möchten wir die traditionellen Methoden aus \secref{ch:MethodenDerDimRed:traditionell} mit
den modernen Methoden aus \secref{ch:MethodenDerDimRed:modern} vergleichen. Dazu gehen wir in
\secref{ch:Vergleich:sec:Methodik} auf die Methodik ein, wobei hier unterschiedliche
Qualitätskriterien und Methoden zur Schätzung der intrinsischen Dimension betrachtet werden. In
\secref{ch:Vergleich:sec:VerwendeteDatensaetze} wird auf die im Vergleich verwendeten Datensätzen
eingegangen und anschließend werden in \secref{ch:Vergleich:sec:Resultate} die Ergebnisse des
empirischen Vergleichs vorgestellt.

\section{Methodik}
\label{ch:Vergleich:sec:Methodik}

In diesem Abschnitt wird auf die Methodik des Vergleichs der Dimensionsreduktionsmethoden
eingegangen. Dazu werden in \subsecref{ch:Vergleich:sec:Methodik:subsec:Qualitaetskriterien} die
hier verwendeten Qualitätskriterien einer Dimensionsreduktion genauer betrachtet. Des Weiteren wird
in \subsecref{ch:Vergleich:sec:Methodik:subsec:SchaetzenDerIntrinsischenDim} kurz die Schätzung der
intrinsischen Dimension behandelt.\todo{hier noch kurz auf das allgemeine Setup eingehen und PCA-AE
	Vergleich erwähnen} \idea{Vergleich von PCA mit Autoencoder

	Hier könnte man vor allem untersuchen, inwiefern ein Autoencoder mit linearen Akt.Funktionen PCA
	identisch ist, sowie schrittweise Nichtlinearität hinzunehmen }
\subsection{Qualitätskriterien der Dimensionsreduktion}
\label{ch:Vergleich:sec:Methodik:subsec:Qualitaetskriterien}
Trotz des immensen Forschungsinteresses für Methoden der Dimensionsreduktion, sind Qualitätskriterien, die die Güte einer Dimensionsreduktion beschreiben, vergleichsweise wenig erforscht. Deshalb gibt es in der Literatur keine eindeutige Kennzahl, die bei einem Vergleich von Dimensionsreduktionsmethoden standardmäßig eingesetzt wird \parencite[vgl.][1 -- 2]{Lee.2009}. Stattdessen bedient man sich mehrerer Kennzahlen, die
unterschiedliche Dinge bestrafen und versucht so die Stärken und Schwächen einer
Dimensionsreduktionsmethode \parencite[486]{Venna.2001} zu erkennen.

\ldots
\todo{hier noch auf den naheliegenden Rekonstruktionsfehler eingehen + erklären wieso er nicht sehr aussagekräftig ist}

Im ausführlichen Benchmark von \textcite{vanderMaaten.2009} wird auf den Generalisierungsfehler
eines 1-Nächste-Nachbar Klassifikators, sowie auf die zwei Kennzahlen
\newterm{Vertrauenswürdigkeit} (engl. \textit{Trustworthiness}) und \newterm{Kontinuität} (engl.
\textit{Continuity}) \parencites{Venna.2001}{Venna.2006} gesetzt. Daneben gibt es noch viele weitere rangbasierte
Qualitätskriterien, welche einheitlich durch die sogenannte \newterm{Co-Ranking Matrix} ausgedrückt
werden können. Ebenso können die Vertrauenswürdigkeit und Kontinuität über die Co-Ranking Matrix
berechnet werden. Für eine ausführliche Behandlung dessen wird auf \textcite{Lee.2009} verwiesen.
Im Folgenden werden die in dieser Arbeit verwendeten Qualitätskriterien kurz vorgestellt.

\subsubsection{Vertrauenswürdigkeit und Kontinuität}
Diese beiden Kennzahlen basieren auf der Idee des Erhalts von Nachbarschaften (engl.
\textit{neighborhood preservation}) einer Dimensionsreduktion. Eine $k$-Nachbarschaft $N_k(i)$
eines Punktes $\vect{x}_i$ ist definiert als die Menge der $k$-nächsten Punkte zu $\vect{x}_i$.
Diese Nachbarschaft wird in einer Dimensionsreduktion erhalten, wenn sich die Menge nicht ändert,
das heißt kein Punkt verlässt die Nachbarschaft und es kommt auch kein anderer neuer Punkt hinzu.

Zum einen kann es passieren, dass Punkte, die \textit{vor} der Projektion weit weg voneinander
lagen, \textit{nach} der Projektion aber nah beieinander sind. Mit anderen Worten können Punkte,
die eigentlich unterschiedlich sind, nun ähnlich erscheinen. Aus diesem Grund sagt man, dass die
Vertrauenswürdigkeit der Dimensionsreduktion niedrig ist. Zum anderen ist der gegenteilige Fall
möglich. Nah beieinander liegende Punkte sind nach der Projektion weit weg voneinander. Dies
reduziert die Kontinuität einer Dimensionsreduktion \parencite[486 -- 487]{Venna.2001}.

\subsubsection{Die Co-Ranking Matrix}
\unsure{Welche Gütemaße, die auf dieser Matrix basieren verwende ich?}

\subsection{Schätzen der intrinsischen Dimension}
\label{ch:Vergleich:sec:Methodik:subsec:SchaetzenDerIntrinsischenDim}

\idea{sehr mathematisch im Detail, Maaten.2009 benutzt den MLE-Schätzer
	\parencite{Levina.2004}. Dazu tendiere ich momentan auch }

\section{Verwendete Datensätze}
\label{ch:Vergleich:sec:VerwendeteDatensaetze}
\idea{Es gibt viele Standard-Benchmark Datensätze die in anderen Arbeiten verwendet werden. Vlt ist es sinnvoll, 1-2 davon auch hier reinzunehmen für die Vergleichbarkeit, und dann 1-2 neue Datensätze,

	insgesamt vlt 2 künstliche Datensätze und 4 real-world Datensätze }
\section{Resultate}
\label{ch:Vergleich:sec:Resultate}
