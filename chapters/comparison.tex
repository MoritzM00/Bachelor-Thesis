%% ==============================
\chapter{Vergleich der Methoden}
\label{ch:Vergleich}
%% ==============================

In \chapref{ch:Dimensionsreduktion} haben wir grundlegende Begriffe geklärt und in
\chapref{ch:MethodenDerDimRed} sechs Methoden der Dimensionsreduktion näher betrachtet. Im jetzigen
Kapitel möchten wir die traditionellen Methoden aus \secref{ch:MethodenDerDimRed:traditionell} mit
den modernen Methoden aus \secref{ch:MethodenDerDimRed:modern} vergleichen. Dazu gehen wir in
\secref{ch:Vergleich:sec:Methodik} auf die Methodik ein, wobei hier unterschiedliche
Qualitätskriterien und Methoden zur Schätzung der intrinsischen Dimension betrachtet werden. In
\secref{ch:Vergleich:sec:VerwendeteDatensaetze} wird auf die im Vergleich verwendeten Datensätzen
eingegangen und anschließend werden in \secref{ch:Vergleich:sec:Resultate} die Ergebnisse des
empirischen Vergleichs vorgestellt.

\section{Methodik}
\label{ch:Vergleich:sec:Methodik}

In diesem Abschnitt wird auf die Methodik des Vergleichs der Dimensionsreduktionsmethoden
eingegangen. Dazu werden in \subsecref{ch:Vergleich:sec:Methodik:subsec:Qualitaetskriterien} die
hier verwendeten Qualitätskriterien einer Dimensionsreduktion genauer betrachtet. Des Weiteren wird
in \subsecref{ch:Vergleich:sec:Methodik:subsec:SchaetzenDerIntrinsischenDim} kurz die Schätzung der
intrinsischen Dimension behandelt.\todo{hier noch kurz auf das allgemeine Setup eingehen und PCA-AE
	Vergleich erwähnen} \idea{Vergleich von PCA mit Autoencoder

	Hier könnte man vor allem untersuchen, inwiefern ein Autoencoder mit linearen Akt.Funktionen PCA
	identisch ist, sowie schrittweise Nichtlinearität hinzunehmen }
\subsection{Qualitätskriterien der Dimensionsreduktion}
\label{ch:Vergleich:sec:Methodik:subsec:Qualitaetskriterien}
Trotz des immensen Forschungsinteresses für Methoden der Dimensionsreduktion, sind Qualitätskriterien, die die Güte einer Dimensionsreduktion beschreiben, vergleichsweise wenig erforscht. Deshalb gibt es in der Literatur keine eindeutige Kennzahl, die bei einem Vergleich von Dimensionsreduktionsmethoden standardmäßig eingesetzt wird \parencite[vgl.][1 -- 2]{Lee.2009}. Stattdessen bedient man sich mehrerer Kennzahlen, die
unterschiedliche Dinge bestrafen und versucht so die Stärken und Schwächen einer
Dimensionsreduktionsmethode \parencite[486]{Venna.2001} zu erkennen.

\ldots
\todo{hier noch auf den naheliegenden Rekonstruktionsfehler eingehen + erklären wieso er nicht sehr aussagekräftig ist}

Im ausführlichen Benchmark von \textcite{vanderMaaten.2009} wird auf den Generalisierungsfehler
eines 1-Nächste-Nachbar Klassifikators, sowie auf die zwei Kennzahlen
\newterm{Vertrauenswürdigkeit} (engl. \textit{Trustworthiness}) und \newterm{Kontinuität} (engl.
\textit{Continuity}) \parencites{Venna.2001}{Venna.2006} gesetzt. Daneben gibt es noch viele weitere rangbasierte
Qualitätskriterien, welche einheitlich durch die sogenannte \newterm{Co-Ranking Matrix} ausgedrückt
werden können. Ebenso können die Vertrauenswürdigkeit und Kontinuität über die Co-Ranking Matrix
berechnet werden. Für eine ausführliche Behandlung dessen wird auf \textcite{Lee.2009} verwiesen.
Im Folgenden werden die in dieser Arbeit verwendeten Qualitätskriterien kurz vorgestellt.

\subsubsection{Vertrauenswürdigkeit und Kontinuität}
Diese beiden Kennzahlen basieren auf der Idee des Erhalts von Nachbarschaften (engl.
\textit{neighborhood preservation}) einer Dimensionsreduktion. Eine $k$-Nachbarschaft
$\set{M}_k(i)$ eines Punktes $\vect{x}_i$ ist definiert als die Menge der $k$-nächsten Punkte zu
$\vect{x}_i$ ($i = 1, \ldots, n$). Analog kann die $k$-Nachbarschaft $\widetilde{\set{M}}_k(i)$ des
dazugehörigen niedrigdimensionalen Punktes $\vect{y}_i$ definiert werden. Diese Nachbarschaft wird
in einer Dimensionsreduktion erhalten, wenn $\set{M}_k(i) = \widetilde{\set{M}}_k(i)$, das heißt
die Nachbarschaften bleiben von der Dimensionsreduktion unverändert.

Zum einen kann es nun passieren, dass Punkte, die \textit{vor} der Projektion weit weg voneinander
lagen, \textit{nach} der Projektion aber nah beieinander sind. Mit anderen Worten können Punkte,
die eigentlich unterschiedlich sind, nun ähnlich erscheinen. Aus diesem Grund sagt man, dass die
Vertrauenswürdigkeit der Dimensionsreduktion niedrig ist. Zum anderen ist der gegenteilige Fall
möglich. Nah beieinander liegende Punkte sind nach der Projektion weit weg voneinander. Dies
reduziert die Kontinuität einer Dimensionsreduktion \parencite[486 -- 487]{Venna.2001}.

Formal definiert man zusätzlich zu den Nachbarschaftsmengen von oben die beiden Mengen
$\set{U}_k(i)$ und $\set{V}_k(i)$ wie folgt:
\begin{gather}
	\set{U}_k(i) =  \left\{ \vect{y}_j\, |\, \vect{x}_j \notin \set{M}_k(i) \land \vect{y}_j \in \widetilde{\set{M}}_k(i) \right\} \\
	\set{V}_k(i) =  \left\{ \vect{x}_j\, |\, \vect{x}_j \in \set{M}_k(i) \land \vect{y}_j \notin \widetilde{\set{M}}_k(i) \right\}
\end{gather}
Diese beiden Mengen bilden lediglich die zwei intuitiv besprochenen Fälle im vorherigen Absatz mathematisch ab. Hierbei entspricht $\set{U}_k(i)$ dem ersten und $\set{V}_k(i)$ dem zweiten Fall.
Damit kann die Vertrauenswürdigkeit $T_k$ als
\begin{equation}
	T_k = 1 - \frac{2}{nk(2n - 3k - 1)} \sum_{i = 1}^{n}\sum_{\vect{y}_j \in \set{U}_k(i) } \left( r(\vect{y}_i, \vect{y}_j) - k \right)
\end{equation}
definiert werden \parencite[487]{Venna.2001}, wobei $r(\vect{y}_i, \vect{y}_j)$ den Rang von $\vect{y}_j$ bezeichnet,
wenn die Datenpunkte absteigend nach der euklidischen Distanz von $\vect{y}_i$ geordnet sind. Der
Term vor der Summation skaliert das Qualitätskriterium so, dass $0 \leq T_k \leq 1$
gilt.\footnote{Dies gilt nur für den Fall, dass $k < n/2$ gilt.} Ein Wert von $T_k = 1­$ spricht
für eine hohe Vertrauenswürdigkeit.

Analog wird die Kontinuität $C_k$ über $\set{V}_k(i)$ wie folgt definiert:
\begin{equation}
	C_k = 1 - \frac{2}{nk(2n - 3k - 1)} \sum_{i = 1}^{n}\sum_{\vect{x}_j \in \set{V}_k(i) } \left( r(\vect{x}_i, \vect{x}_j) - k \right)
\end{equation}
wobei $r(\vect{x}_i, \vect{x}_j)$ nun den Rang zwischen den Datenpunkten in der hochdimensionalen Repräsentation bezeichnet \parencite[487]{Venna.2001}. Auch hier gilt $0 \leq C_k \leq 1$ und höher ist besser. Die Kontinuität
misst also, wie gut die ursprünglichen Nachbarschaften erhalten werden.

\subsubsection{Die Co-Ranking Matrix}
\unsure{Welche Gütemaße, die auf dieser Matrix basieren verwende ich?}

\subsection{Schätzen der intrinsischen Dimension}
\label{ch:Vergleich:sec:Methodik:subsec:SchaetzenDerIntrinsischenDim}

\idea{sehr mathematisch im Detail, Maaten.2009 benutzt den MLE-Schätzer
	\parencite{Levina.2004}. Dazu tendiere ich momentan auch }

\section{Verwendete Datensätze}
\label{ch:Vergleich:sec:VerwendeteDatensaetze}
\idea{Es gibt viele Standard-Benchmark Datensätze die in anderen Arbeiten verwendet werden. Vlt ist es sinnvoll, 1-2 davon auch hier reinzunehmen für die Vergleichbarkeit, und dann 1-2 neue Datensätze,

	insgesamt vlt 2 künstliche Datensätze und 4 real-world Datensätze }
\section{Resultate}
\label{ch:Vergleich:sec:Resultate}
