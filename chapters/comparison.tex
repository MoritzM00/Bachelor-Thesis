%% ==============================
\chapter{Vergleich der Methoden}
\label{ch:Vergleich}
%% ==============================

In \chapref{ch:Dimensionsreduktion} wurden grundlegende Begriffe geklärt und in
\chapref{ch:MethodenDerDimRed} sechs Methoden der Dimensionsreduktion näher betrachtet. Im jetzigen
Kapitel möchten werden die statistischen Methoden aus \secref{ch:MethodenDerDimRed:statistisch} mit
den Machine Learning Methoden aus \secref{ch:MethodenDerDimRed:modern} empirisch auf künstlichen
und natürlichen Datensätzen vergleichen. Dazu wird im Folgenden in
\secref{ch:Vergleich:sec:Methodik} auf die Methodik des Vergleichs eingegangen, indem die Schätzung
der intrinsischen Dimension und die eingesetzten Qualitätskriterien erläutert. Außerdem werden in
\secref{ch:Vergleich:sec:VerwendeteDatensaetze} die verwendeten Datensätze vorgestellt und
anschließend werden in \secref{ch:Vergleich:sec:Resultate} die Resultate des empirischen Vergleichs
diskutiert.

\section{Methodik}
\label{ch:Vergleich:sec:Methodik}

Um die statistischen Methoden mit den Machine Learning Ansätzen zu vergleichen, wird die
Performance der Methoden auf mehreren künstlichen sowie natürlichen Datensätzen mit der
Vertrauenswürdigkeit, der Kontinuität und dem $\lcmc$-Kriterium gemessen. Diese Kriterien werden
jeweils für mehrere Nachbarschaftsgrößen berechnet, um eine größere Aussagekraft über die Güte der
gefundenen niedrigdimensionalen Repräsentation zu erreichen. Die Qualitätskriterien werden in
\subsecref{ch:Vergleich:sec:Methodik:subsec:Qualitaetskriterien} eingehend erläutert. Für den
Vergleich werden zwei künstliche und vier natürliche Datensätze verwendet, die in
\secref{ch:Vergleich:sec:VerwendeteDatensaetze} genauer vorgestellt werden. Insgesamt soll damit
ein Überblick über die Stärken und Schwächen der statistischen und der Machine Learning Methoden
geschafft werden. Wie in \subsecref{ch:MethodenDerDimRed:ML:AE:VerhaeltnisPCA} erwähnt, besteht
zwischen Autoencodern und der Hauptkomponentenanalyse eine enge Verbindung. Neben dem Vergleich der
zwei Gruppen wird daher in \secref{ch:Vergleich:sec:Resultate:PCA_linearAE} der Zusammenhang
zwischen der Hauptkomponentenanalyse und einem linearen Autoencoder genauer untersucht.

\subsection{Qualitätskriterien der Dimensionsreduktion}
\label{ch:Vergleich:sec:Methodik:subsec:Qualitaetskriterien}
Wie bereits in \secref{ch:Dimensionsreduktion} erläutert, hat die Dimensionsreduktion das Ziel einer möglichst \enquote{verlustfreien} Transformation der ursprünglichen Repräsentation in eine latente Repräsentation von geringerer Dimension. Der Rekonstruktionsfehler, den man beispielsweise vom Autoencoder kennt, ist jedoch wie \textcite[18]{vanderMaaten.2009} hervorhebt, nicht sehr aussagekräftig für die Güte einer Dimensionsreduktion. Hinzu kommt, dass der Rekonstruktionsfehler nicht für alle Methoden berechnet werden kann, da eine inverse Transformation der niedrigdimensionalen in die ursprüngliche Repräsentation benötigt wird. Damit fällt der Rekonstruktionsfehler als geeignetes Qualitätskriterium heraus. Das immense Forschungsinteresse für Methoden der Dimensionsreduktion hat daher mit der Zeit dafür gesorgt, dass immer mehr Qualitätskriterien entwickelt wurden. Deshalb gibt es in der Literatur keine eindeutige Kennzahl, die bei einem Vergleich von Dimensionsreduktionsmethoden standardmäßig eingesetzt wird \parencite[vgl.][1 -- 2]{Lee.2009}. Stattdessen bedient man sich mehrerer Kennzahlen, die
unterschiedliche Dinge bestrafen und versucht so die Stärken und Schwächen einer
Dimensionsreduktionsmethode zu erkennen \parencite[486]{Venna.2001}. Die im Folgenden vorgestellten Qualitätskriterien sind die
\newterm{Vertrauenswürdigkeit}, die \newterm{Kontinuität} und das $\lcmc$-Kriterium versuchen die
Güte mithilfe von Rängen zu quantifizieren.

Im ausführlichen Benchmark von \textcite{vanderMaaten.2009} wird auf den Generalisierungsfehler
eines 1-Nächste-Nachbar Klassifikators, sowie auf die zwei Kennzahlen
\newterm{Vertrauenswürdigkeit} (engl. \textit{Trustworthiness}) und \newterm{Kontinuität} (engl.
\textit{Continuity}) \parencites{Venna.2001}{Venna.2006} gesetzt. Daneben gibt es noch viele weitere rangbasierte
Qualitätskriterien, welche einheitlich durch die sogenannte \newterm{Co-Ranking Matrix} ausgedrückt
werden können. Ebenso können die Vertrauenswürdigkeit und Kontinuität über die Co-Ranking Matrix
berechnet werden. Für eine ausführliche Behandlung dessen wird auf \textcite{Lee.2009} verwiesen.
Im Folgenden werden die in dieser Arbeit verwendeten Qualitätskriterien kurz vorgestellt.

\subsubsection{Vertrauenswürdigkeit und Kontinuität}
Diese beiden Kennzahlen basieren auf der Idee des Erhalts von Nachbarschaften (engl.
\textit{neighborhood preservation}) einer Dimensionsreduktion. Sie bilden also ab, wie gut die
lokale Struktur erhalten wird. Eine $K$-Nachbarschaft $\set{M}_i(K)$ eines Punktes $\vect{x}_i$ ist
definiert als die Menge der Indizes der $K$-nächsten Punkte zu $\vect{x}_i$ ($i = 1, \ldots, n$).
Analog kann die $K$-Nachbarschaft $\widetilde{\set{M}}_i(K)$ des dazugehörigen niedrigdimensionalen
Punktes $\vect{y}_i$ definiert werden. Diese Nachbarschaft wird in einer Dimensionsreduktion
erhalten, wenn $\set{M}_i(K) = \widetilde{\set{M}}_i(K)$, das heißt die Nachbarschaften bleiben von
der Dimensionsreduktion unverändert.

Zum einen kann es nun passieren, dass Punkte, die \textit{vor} der Projektion weit weg voneinander
lagen, \textit{nach} der Projektion aber nah beieinander sind. Mit anderen Worten können Punkte,
die eigentlich unterschiedlich sind, nun ähnlich erscheinen. Aus diesem Grund sagt man, dass die
Vertrauenswürdigkeit der Dimensionsreduktion niedrig ist. Zum anderen ist der gegenteilige Fall
möglich. Nah beieinander liegende Punkte sind nach der Projektion weit weg voneinander. Dies
reduziert die Kontinuität einer Dimensionsreduktion \parencite[486 -- 487]{Venna.2001}.

Formal definiert man zusätzlich zu den Nachbarschaftsmengen von oben die beiden Mengen
$\set{U}_i(K)$ und $\set{V}_i(K)$ wie folgt:
\begin{gather}
	\set{U}_i(K) =  \left\{ j \in \N \mid j \notin \set{M}_i(K) \land j \in \widetilde{\set{M}}_i(K) \right\} \, , \\
	\set{V}_i(K) =  \left\{ j \in \N \mid j \in \set{M}_i(K) \land j \notin \widetilde{\set{M}}_i(K) \right\} \, .
\end{gather}
Diese beiden Mengen bilden lediglich die zwei intuitiv besprochenen Fälle im vorherigen Absatz mathematisch ab. Hierbei entspricht $\set{U}_i(K)$ dem ersten und $\set{V}_i(K)$ dem zweiten Fall.
Damit kann die Vertrauenswürdigkeit $T(K)$ als
\begin{equation}
	T(K) = 1 - \frac{2}{nK(2n - 3K - 1)} \sum_{i = 1}^{n}\sum_{j \in \set{U}_i(K) } \left( r­_{\vect{y}}(i, j) - K \right)
\end{equation}
definiert werden \parencite[487]{Venna.2001}, wobei $r_{\vect{y}}(i, j)$ den Rang von des niedrigdimensionalen Vektors
$\vect{y}_j$ bezeichnet, wenn die Datenpunkte absteigend nach der euklidischen Distanz von
$\vect{y}_i$ geordnet sind. Der Term vor der Summation skaliert das Qualitätskriterium so, dass $0
	\leq T(K) \leq 1$ gilt.\footnote{Dies gilt nur für den Fall, dass $K < n/2$ gilt.} Ein Wert von
$T(K) = 1­$ spricht für eine hohe Vertrauenswürdigkeit.

Analog wird die Kontinuität $C(K)$ über $\set{V}_i(K)$ wie folgt definiert
\begin{equation}
	C(K) = 1 - \frac{2}{nK(2n - 3K - 1)} \sum_{i = 1}^{n}\sum_{j \in \set{V}_i(K) } \left( r_{\vect{x}}(i, j) - K \right) \, ,
\end{equation}
wobei $r_{\vect{x}}(i, j)$ nun den Rang zwischen den Datenpunkten in der hochdimensionalen Repräsentation bezeichnet \parencite[487]{Venna.2001}. Auch hier gilt $0 \leq C(K) \leq 1$ und höher ist besser. Die Kontinuität
misst also, wie gut die ursprünglichen Nachbarschaften erhalten werden. \idea{Man könnte die
	Gesamtqualität dann auch als den gewichteten Mittelwert der beiden Kennzahlen T\&C definieren \parencite[1435]{Lee.2009}} \idea{hier erwähnen, dass man mehrere Werte K nimmt und dann das ganze
	plottet -> AUC berechnen?}

\subsubsection{Die Co-Ranking Matrix}
Ein Eintrag $q_{kl}$ der Co-Ranking Matrix $\mat{Q}$ ist die Anzahl der Paare von Datenpunkten $(i,
	j)$, die den Rang $r_{\vect{x}}(i, j) = k$ in der hochdimensionalen und den Rang $r_{\vect{y}}(i,
	j) = l$ in der niedrigdimensionalen Repräsentation haben.

\idea{Welche Gütemaße, die auf dieser Matrix basieren verwende ich?
	Diese werden in \textcite{Lee.2009} vorgestellt, darunter
	\begin{enumerate}
		\item local continuity meta criterion (LCMC)
		\item Mean relative Rank error (ähnliche Idee wie T\&C)
		\item andere Kennzahlen, die jeweils unterschiedliche Teile der Co-Ranking Matrix betrachten. Um diese z
		      verstehen, muss man noch weitere Begriffe wie (milde, harte) ($k$)-Intrusionen und Extrusionen
		      erklären. Kann dann relativ lang werden dieser Abschnitt
	\end{enumerate}
	LCMC fokussiert mehr darauf was in einer Projektion gut läuft (T\&C fokussieren auf das was schlecht läuft). Und es hat den Vorteil nur ein einziger Skalar zu sein.
}

\subsubsection{Local Continuity Meta Criterion}

\subsection{Schätzen der intrinsischen Dimension}
\label{ch:Vergleich:sec:Methodik:subsec:SchaetzenDerIntrinsischenDim}

Bis jetzt wurde immer angenommen, dass die intrinsische Dimension $d$ der Daten bekannt ist, da die
meisten Dimensionsreduktionsmethoden die intrinsische Dimension nicht selbst berechnen. Das
Schätzen der intrinsischen Dimension ist also ein nicht unwichtiges Teilproblem der
Dimensionsreduktion, da eine Unterschätzung von $d$ dazu führt, dass relevante Strukturen
zwangsweise verloren gehen \parencite[1]{Levina.2004}. Erschwert wird dieses Problem durch die Tatsache, dass es sehr viele
Definitionen der intrinsischen Dimension und damit auch sehr viele unterschiedliche Schätzer gibt.
Im Folgenden soll ein kurzer Überblick verschafft werden, jedoch geht eine detaillierte Behandlung
der Schätzung über den Rahmen dieser Arbeit hinaus. Daher wird für einen Überblick und Vergleich
dieser Schätzer auf \textcites{Campadelli.2015}{Bac.2021}{Verveer.1995} verwiesen.

In \secref{ch:Dimensionsreduktion:MannigfaltigkeitenIntrinsDim} haben wir die \textit{topologische
	Dimension} kennengelernt, welche sich in der Literatur zur Strukturerkennung durchgesetzt hat \parencite[1]{Campadelli.2015}. Allerdings bringt diese Definition praktische Schwierigkeiten mit sich,
weswegen die meisten Schätzer der intrinsischen Dimension auf der damit verwandten
\textit{fraktalen Dimension} wie zum Beispiel der Schätzer der Korrelationsdimension \parencite{Camastra.2002} basieren. Daneben gibt es noch Nächste-Nachbar-basierte Schätzer \parencite[1]{Campadelli.2015}. Zu dieser Kategorie gehört auch der weit verbreitete und in dieser
Arbeit verwendete \newterm{Maximum Likelihood Schätzer} von \textcite{Levina.2004}. Diese Schätzer
betrachten die Verteilung der Nachbarschaft eines Punktes $\rvect{x}$ als Funktion der
intrinsischen Dimension -- üblicherweise innerhalb einer kleinen Kugel um $\rvect{x}$
\parencite[8]{Campadelli.2015}. Der Maximum Likelihood Schätzer nimmt an, dass die Beobachtungen, die
in einer solchen Kugel liegen, einem homogenen Poisson-(Zähl-)Prozess folgen
\parencite[2]{Levina.2004}. Dieser Prozess hängt von $d$ ab, weshalb mittels der Maximum Likelihood
Methode ein Schätzwert $\estNormal{d}$ für einen fixen Punkt $\rvect{x}_i$ als
\begin{equation}
	\estNormal{d}_K(\vect{x}_i) = \left( \frac{1}{K - 1} \sum_{j=1}^{K - 1} \log \frac{T_K(\vect{x}_i)}{T_j(\vect{x}_i)} \right)^{-1}
\end{equation}
berechnet werden kann \parencite[4]{Levina.2004}. Hierbei ist $K$ die Anzahl der nächste Nachbarn und $T_{K}(\vect{x}_i)$ die
euklidische Distanz von $\vect{x}_i$ zu seinem $K$-ten Nachbar. Dies ist jedoch nur eine lokale
Schätzung für einen fixen Punkt $\vect{x}_i$. Um eine globale Schätzung zu erhalten, wird der
Mittelwert über alle Beobachtungen für mehrere Werte von $K$ gebildet.
\section{Verwendete Datensätze}
\label{ch:Vergleich:sec:VerwendeteDatensaetze}
Es werden sowohl künstliche als auch natürliche Datensätze eingesetzt, um Eigenschaften der
verschiedenen Methoden miteinander zu vergleichen. Eine Übersicht über die Dimensionen und Stichprobengrößen der verwendeten Datensätze befindet sich in Tabelle \ref{tab:uebersicht-datensaetze}.

\subsection{Künstliche Datensätze}
\label{ch:Vergleich:sec:VerwendeteDatensaetze:kuenstlich}
Zu den künstlichen Datensätzen gehört die weit
verbreitete \textit{Swiss Roll} und der \textit{Twin Peaks} Datensatz,
\begin{figure}[ht]
	\label{fig:ArtificialDatasets}
	\begin{center}
		\input{\figures/artificial_datasets.pgf}
	\end{center}
	\caption[Künstliche Datensätze]{\figleft Die Swiss Roll. Die intrinsische Dimension beträgt zwei weil die Daten auf einer \enquote{eingerollten Ebene} liegen. Die Dimensionsreduktionsmethoden müssen die Swiss Roll \enquote{entfalten}, um eine zweidimensionale Repräsentation zu erhalten. \figright Der Twin Peaks Datensatz. Dieser besteht aus je zwei spitzen Bergen, die nach oben und unten zeigen. Auch dieser Datensatz hat eine intrinsische Dimension von zwei, denn die Berge können \enquote{plattgedrückt} werden, womit man eine zweidimensionale Repräsentation erhält.}
\end{figure}
die in \figref{fig:ArtificialDatasets} dargestellt sind.
Beide künstlichen Datensätze haben eine extrinsische Dimension von drei und eine intrinsische
Dimension von zwei. Dies erlaubt eine visuelle Betrachtung der Datensätze und der gefundenen
latenten Räume, schränkt aber gleichzeitig die Architektur eines (unterbestimmten) Autoencoders
sehr ein. Künstliche Datensätze alleine sind wenig aussagekräftig für die tatsächliche Performance
einer Methode, weswegen zusätzlich vier\unsure{subject to change} natürliche Datensätze hinzugezogen werden.

\subsection{Natürliche Datensätze}
\label{ch:Vergleich:sec:VerwendeteDatensaetze:natuerlich}
Natürliche
Datensätze weisen empirischen Ergebnissen zufolge \addref oft komplexe nichtlineare Zusammenhänge
auf und sind daher für die Dimensionsreduktion anspruchsvoller als kleine künstlich generierte
Datensätze. Der Nachteil besteht darin, dass die intrinsische Dimension in der Regel deutlich über
zwei liegt und daher der latente Raum nicht visualisiert werden kann. Nichtsdestotrotz liefern die
Qualitätskriterien hinreichende gute Indizien für die Performance der Methoden. Bei den natürlichen
Datensätzen wurden größtenteils Bilddatensätze, aber auch ein Textdatensatz ausgewählt, da diese eine
sehr hohe extrinsische Dimension aufweisen und daher für die Dimensionsreduktion gut geeignet sind.
Konkret wurde (1) der \textit{MNIST}-Datensatz \parencite{LeCun.2010}, (2) der \textit{Olivetti Face}-Datensatz
\footnote{\url{https://cam-orl.co.uk/facedatabase.html}}, (3) der \textit{Labeled Faces in the
	Wild} (LFW) Datensatz \parencite{GaryB.Huang.2007}, (4) der \textit{Facial Emotion Recognition} (FER) Datensatz \parencite{DumitruIanGoodfellowWillCukierskiYoshuaBengio.2013} und (5) der \textit{20
	Newsgroups}\footnote{\url{http://qwone.com/~jason/20Newsgroups/}} Datensatz ausgewählt, um die
Performance der Dimensionsreduktionsmethoden auf natürlichen Datensätzen zu evaluieren. Der weit
verbreitete MNIST-Datensatz besteht aus 60 000 Grauton-Bildern von handgeschriebenen Zahlen in der
Auflösung $28 \times 28$. Die Anzahl der Pixel und damit die extrinsische Dimension beträgt 784.
Der \textit{Olivetti Face}-Datensatz enthält Bilder von Gesichtern aus zehn unterschiedlichen
Positionen von 40 Personen und ist damit der kleinste natürliche Datensatz in diesem Vergleich mit
400 Bildern. Die Bilder haben eine Auflösung von $64 \times 64$, was einer extrinsischen Dimension
von 4096 entspricht. Der LFW-People-Datensatz enthält insgesamt über 13 000 Bilder von Gesichtern,
jedoch wurde hier eine Teilmenge ausgewählt, sodass jede Person mindestens 30 mal vorkommt. Dies
resultiert in einer Stichprobengröße von 2370. Die Bilder haben eine Auflösung von $62 \times 47$
und damit eine extrinsische Dimension von 2914. Der FER-2013 Datensatz besteht aus 28 709 Bildern
von Gesichtern mit sechs unterschiedlichen Emotionen. Die Bilder haben eine Auflösung von $48
	\times 48$ und sind damit 2304-dimensional. Beispiele der Bild-Datensätze sind in
\figref{fig:Dataset_samples} zu finden.
\begin{figure}
	\label{fig:Dataset_samples}
	\begin{center}
		\input{\figures/dataset_samples.pgf}
	\end{center}
	\caption{Beispielbilder der natürlichen Datensätze}
\end{figure}

\begin{table}[]
	\centering
	\begin{tabular}{@{}cccc@{}}
		\toprule
		Datensatz      & extrinsische Dimension $D$ & intrinsische Dimension $d$ & Stichprobengröße $n$ \\ \midrule
		Swiss Roll     & 3                          & 2                          & 5000                 \\
		Twin Peaks     & 3                          & 2                          & 5000                 \\
		MNIST          & 784                        & 10                         & 60000                \\
		Olivetti Faces & 4096                       & ?                          & 400                  \\
		LFW-People     & 2914                       & ?                          & 2370                 \\
		FER-2013       & ?                          & ?                          & ?                    \\ \bottomrule
	\end{tabular}
	\caption{Übersicht über die Dimensionen und Stichprobengröße der verwendeten Datensätze}
	\label{tab:uebersicht-datensaetze}
\end{table}
\section{Resultate}
\label{ch:Vergleich:sec:Resultate}

In diesem Abschnitt werden die Resultate des empirischen Vergleichs vorgestellt. Dazu werden die
Werte der verschiedenen Qualitätskriterien auf den künstlichen und natürlichen Datensätzen in
Abhängigkeit der Nachbarschaftsgröße $K$ abgebildet. In
\secref{ch:Vergleich:sec:Resultate:kuenstlich} werden die Ergebnisse auf künstlichen Datensätzen
und in \secref{ch:Vergleich:sec:Resultate:natuerlich} die Ergebnisse auf den natürlichen
Datensätzen diskutiert.

\subsection{Resultate auf künstlichen Datensätzen}
\label{ch:Vergleich:sec:Resultate:kuenstlich}

Wie in \figref{fig:SwissRollMetrics}
\begin{figure}[ht]
	\label{fig:SwissRollMetrics}
	\begin{center}
		\input{\figures/SwissRoll_comparison.pgf}
	\end{center}
	\caption[Swiss Roll Qualitätskriterien]{Qualitätskriterien $T(K)$,  $C(K)$ und $\lcmc(K)$ für den Swiss Roll Datensatz. LLE schneidet mit Abstand am besten ab. Die restlichen Methoden unterscheiden sich nicht deutlich, jedoch kann sich die Hauptkomponentenanalyse (PCA) von den anderen drei Methoden (AE, Kernel PCA und CAE) hinsichtlich der Vertrauenswürdigkeit und dem $\lcmc$-Kriterium etwas absetzen. (Eigene Darstellung)}
\end{figure}
und \figref{fig:TwinPeaksMetrics}
\begin{figure}[ht]
	\label{fig:TwinPeaksMetrics}
	\begin{center}
		\input{\figures/TwinPeaks_comparison.pgf}
	\end{center}
	\caption[Twin Peaks Qualitätskriterien]{Qualitätskriterien $T(K)$, $C(K)$ und $\lcmc(K)$ für den Twin Peaks Datensatz. Auch hier zeigt LLE die beste Performance hinsichtlich allen drei Kriterien, gefolgt von Kernel PCA und dem Contractive Autoencoder (CAE). Am schlechtesten schneiden der klassische Autoencoder und die Hauptkomponentenanalyse ab. Letztere kann vor allem auf der Vertrauenswürdigkeit nicht mithalten. (Eigene Darstellung)}
\end{figure}
erkennbar schneidet Locally Linear Embedding hinsichtlich allen drei Qualitätskriterien am besten ab, wobei im $\lcmc$ der größte Abstand zu den restlichen Methoden ist. Die anderen vier Methoden sind relativ ähnlich. Kernel PCA und der Contractive Autoencoder können sich auf dem Twin Peaks Datensatz von den klassischen Varianten der PCA und des Autoencoders abheben, nicht jedoch auf dem Swiss Roll Datensatz.

\subsection{Resultate auf natürlichen Datensätzen}
\label{ch:Vergleich:sec:Resultate:natuerlich}

Die Qualitätskriterien auf den natürlichen Datensätzen zeigen ein etwas anderes Bild, als es bei
den künstlichen Datensätzen der Fall war. Die starke Performance von Locally Linear Embedding setzt
sich nicht auf den natürlichen hochdimensionalen Datensätzen fort. Für die Olivetti Faces
(\figref{fig:OlivettiFacesMetrics}), den FER 2013 (\figref{fig:FER2013Metrics}) und den LFW People
Datensatz (\figref{fig:LfwPeopleMetrics}) schneidet LLE auf allen drei Kriterien am schlechtesten
ab. Zusätzlich nehmen die Qualitätskriterien von LLE mit größer werdender Nachbarschaftsgröße $K$
deutlicher abnimmt als bei den restlichen Methoden. Dies ist wahrscheinlich der lokalen Natur von
LLE geschuldet.

\begin{figure}[ht]
	\label{fig:MNISTMetrics}
	\begin{center}
		\input{\figures/MNIST_comparison.pgf}
	\end{center}
	\caption[MNIST Qualitätskriterien]{Qualitätskriterien $T(K)$, $C(K)$ und $\lcmc(K)$ für den MNIST Datensatz. (Eigene Darstellung)}
\end{figure}

\begin{figure}[ht]
	\label{fig:OlivettiFacesMetrics}
	\begin{center}
		\input{\figures/OlivettiFaces_comparison.pgf}
	\end{center}
	\caption[Olivetti Faces Qualitätskriterien]{Qualitätskriterien $T(K)$, $C(K)$ und $\lcmc(K)$ für den Olivetti Faces Datensatz. (Eigene Darstellung)}
\end{figure}

\begin{figure}[ht]
	\label{fig:LfwPeopleMetrics}
	\begin{center}
		\input{\figures/LfwPeople_comparison.pgf}
	\end{center}
	\caption[LFW People Qualitätskriterien]{Qualitätskriterien $T(K)$, $C(K)$ und $\lcmc(K)$ für den LFW People Datensatz. (Eigene Darstellung)}
\end{figure}

\begin{figure}[ht]
	\label{fig:FER2013Metrics}
	\begin{center}
		\input{\figures/FER2013_comparison.pgf}
	\end{center}
	\caption[FER2013 Qualitätskriterien]{Qualitätskriterien $T(K)$, $C(K)$ und $\lcmc(K)$ für den FER 2013 Datensatz. (Eigene Darstellung)}
\end{figure}

\subsection{PCA und lineare Autoencoder}
\label{ch:Vergleich:sec:Resultate:PCA_linearAE}