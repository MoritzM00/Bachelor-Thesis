%% ==============================
\chapter{Methoden der Dimensionsreduktion}
\label{ch:MethodenDerDimRed}
%% ==============================

Nachdem wir nun die Motivation und Idee hinter der Dimensionsreduktion in \chapref{ch:Enleitung} und die mathematische Formulierung
in \chapref{ch:Dimensionsreduktion} allgemein angeschaut haben,
werden nun einige Methoden zur Dimensionsreduktion vorgestellt.

In jüngster Zeit haben vor allem verschiedenste Varianten von neuronale Netzen einen hohen Grad an Aufmerksamkeit durch bahnbrechende Errungenschaften in Gebieten der Spracherkennung oder \textit{Computer Vision} erlangt. Fraglich ist, ob diese neuen Algorithmen auch auf dem Bereich der Dimensionsreduktion einen entscheidenden Fortschritt gemacht haben. Deshalb unterteilen wir die Algorithmen in \textit{traditionelle}
und \textit{moderne} Methoden, um diese später in \chapref{ch:Vergleich} gegenüberstellen zu können. Mit traditionellen Methoden
sind statistische Methoden wie die Hauptkomponentenanalyse (\chapref{ch:MethodenDerDimRed:traditionell:PCA}) oder andere etablierte
Methoden der Dimensionsreduktion gemeint, wohingegen moderne Methoden auf neuere Entwicklungen wie neuronale Netze und die Varianten davon abzielt. Allerdings ist hier aus jeder Kategorie nur eine kleine repräsentative Auswahl getroffen worden. Weitere wichtige Algorithmen, die hier nicht vorgestellt werden können sind beispielsweise \dots \todo{Nachweise für Algorithmen + aufzählen}.

\section{Traditionelle Methoden}
\label{ch:MethodenDerDimRed:traditionell}

Zuerst widmen wir uns den traditionellen Methoden der Dimensionsreduktion.
Dazu gehören die \newterm{Hauptkomponentenanalyse} (engl. \textit{principal components analysis} (PCA)) in \chapref{ch:MethodenDerDimRed:traditionell:PCA},
die nicht-lineare Erweiterung der
Hauptkomponentenanalyse (\chapref{ch:MethodenDerDimRed:traditionell:kPCA})
und die für die Visualisierung sehr verbreitete Methode \newterm{t-distributed stochastic neighborhood embedding} (t-SNE).


\newpage

%% ==============================
\subsection{Principal Component Analysis}
\label{ch:MethodenDerDimRed:traditionell:PCA}
\nomenclature[Z]{PCA}{Principal Component Analysis}

%% ==============================
\subsection{Kernel Principal Component Analysis}
\label{ch:MethodenDerDimRed:traditionell:kPCA}
\nomenclature[Z]{kPCA}{Kernel Principal Component Analysis}

%% ==============================
\subsection{t-distributed Stochastic Neighborhood Embedding}
\label{ch:MethodenDerDimRed:traditionell:t-SNE}
\nomenclature[Z]{t-SNE}{t-distributed Stochastic Neighborhood Embedding}

\newpage

%% ==============================
%% ==============================
\section{Moderne Methoden}
\label{ch:MethodenDerDimRed:modern}
%% ==============================
Hier werden Moderne Methoden vorgestellt.

\subsection{Autoencoder}
\label{ch:MethodenDerDimRed:modern:AE}
\nomenclature[Z]{AE}{Autoencoder}

\begin{figure}[h]
	\label{fig:5-layer-Autoencoder}
	\begin{center}
		\includegraphics[width=\textwidth]{5_layer_AE.pdf}
		\caption{Autoencoder mit fünf Schichten und dreidimensionalem Bottleneck.}
	\end{center}
\end{figure}

\subsection{Variational Autoencoder}
\label{ch:MethodenDerDimRed:modern:VAE}
\nomenclature[Z]{VAE}{Variational Autoencoder}

\subsection{Self-Organizing Maps}
\label{ch:MethodenDerDimRed:modern:SOM}
\nomenclature[Z]{SOM}{Self-Organizing Map}
