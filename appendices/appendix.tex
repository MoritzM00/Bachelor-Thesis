%% appendix.tex
%%

\chapter{Appendix}
\label{ch:Appendix}

\section{Autoencoder-Architekturen und Trainingsdetails}
\label{ch:Appendix:Architektur-Details}
In diesem Abschnitt werden Details zu den Autoencoder-Architekturen und Details zum Training der Autoencoder erläutert. Zuerst werden die Architekturen der klassischen vollvernetzten Autoencoder (AE), dann die Architekturen der Convolutional Autoencoder (ConvAE) und zuletzt die Architektur der Contractive Autoencoder (CAE) spezifiziert. Anschließend wird der benutzte Optimierer und andere Trainings-Details genannt. Da die Architekturen
vom Datensatz abhängen, werden diese in den folgenden Tabellen nach dem Datensatz gruppiert. Dabei steht $\text{FC}_{x}$ für eine vollvernetzte Schicht mit $x$ Neuronen. BN steht für \textit{Batch Normalization} \parencite{Ioffe.2015} und wird in vollvernetzten Autoencoder und Convolutional Autoencoder eingesetzt,
da die Autoencoder mit Batch Normalization hinsichtlich der Qualitätskriterien besser abschnitten
haben als ohne. $\text{Conv}_n$ steht für eine Convolutional Schicht mit $n$ Filter. In
Convolutional Neural Networks ist es üblich, dass nach einer faltenden Schicht eine sogenannte
\textit{Pooling}-Schicht \parencite[339 -- 345]{Goodfellow.2016} kommt, die die Größe des Inputs zwar verkleinert, dies aber
\textit{ohne} trainierbare Gewichte tut. In Autoencodern soll die Inputgröße im Encoder ebenfalls
sukzessive verkleinert werden, allerdings wollen wir lernen, wie man sie verkleinert. Daher wird
hier anstelle von Pooling-Schichten die Schrittgröße (engl. \textit{Stride}) in der faltenden
Schicht auf einen Wert größer Eins gesetzt. Dies bedeutet, dass bei der Faltungsoperation Pixel
ausgelassen werden und dadurch die Größe des Inputs verkleinert wird. Die Schrittgröße wurde daher
für alle Convolutional Schichten auf zwei gesetzt. In einem Convolutional Autoencoder werden im
Decoder Convolutional Schichten gegen Transposed Convolutional Schichten \parencite[siehe][]{Zeiler.2010} ausgetauscht.

\tabref{tab:uebersicht-autoencoder-non-image} enthält die Encoder-Architekturen der vollvernetzten und Contractive Autoencoder auf dem Swiss Roll-, Twin Peaks- und ICMR-Datensatz.
\input{tables/non_image_architectures.tex}Der Convolutional Autoencoder ist auf diesen Datensätzen nicht anwendbar und daher nicht in der Tabelle aufzufinden. Die Architekturen auf den Bilddatensätzen sind in zwei weiteren Tabellen aufgelistet. Die Architekturen für MNIST und Fashion MNIST sind in \tabref{tab:uebersicht-autoencoder-mnist}
\input{tables/image_architectures.tex} und für die kleineren Bilddatensätze ORL und FER in \tabref{tab:uebersicht-autoencoder-small}.
\input{tables/small_image_datasets_architectures.tex}

Alle Autoencoder benutzen das \textit{PyTorch}-Framework, wobei \textit{Skorch} für die
Kompatibilität mit anderen \textit{Scikit-Learn} Algorithmen eingesetzt wird. Als Optimierer wird
\textit{Adam} verwendet, der häufig für das Trainieren neuronaler Netze gegenüber anderen
Optimierern wie \textit{Stochastic Gradient Descent} (SGD) präferiert wird. Die Lernrate $\eta$
wird mittels eines exponentiellen Verfalls nach jeder Epoche aktualisiert. Dazu wird $\eta$ nach
jeder Epoche $t = 1, \ldots, t_{\text{max}}$ mit einem Wert $\gamma$ multipliziert. Dieser Wert
wird für alle Autoencoder auf $\gamma = \num{0,9}$ gesetzt. Der klassische Autoencoder wird für
maximal 100 Epochen, der Contractive Autoencoder für maximal 50 Epochen und die Convolutional
Autoencoder für maximal 150 Epochen trainiert. Das Training wird frühzeitig beendet, wenn sich der
Validierungsfehler innerhalb von 20 Epochen nicht mehr verbessert. Die Größe eines Batches ist
datensatzabhängig nach Stichprobengröße gewählt worden und beträgt 64 für die Swiss Roll und Twin
Peaks, 32 für ORL und ICMR, sowie 128 für MNIST, Fashion MNIST und FER.

\section{Qualitätskriterien für die Datensätze}
\label{ch:Appendix:Qualitaetskriterien}

In diesem Abschnitt werden die Abbildungen der Qualitätskriterien für die restlichen Datensätze
gesammelt. In \figref{fig:TwinPeaksMetrics} sind die Qualitätskriterien für die Twin Peaks, in
\figref{fig:ICMRMetrics} die Qualitätskriterien für ICMR, in \figref{fig:OlivettiFacesMetrics} die
Qualitätskriterien für den ORL Datensatz, in \figref{fig:FashionMNISTMetrics} für den Fashion
MNIST-Datensatz und in \figref{fig:FER2013Metrics} für den FER-Datensatz.
\begin{figure}[ht]
	\begin{center}
		\includegraphics{TwinPeaks_comparison.pdf}
	\end{center}
	\caption[Qualitätskriterien für den Twin Peaks-Datensatz]{Die Vertrauenswürdigkeit und Kontinuität der Dimensionsreduktion, sowie das Local Continuity Meta-Criterion (LCMC) für den Twin Peaks-Datensatz. Locally Linear Embedding (LLE) schneidet wie bei der Swiss Roll insgesamt am besten ab, gefolgt von der Kernel PCA und vom Autoencoder. Lediglich der Contractive Autoencoder (CAE) und PCA fallen auf diesem künstlichen Datensatz etwas zurück, wobei die Vertrauenswürdigkeit der Dimensionsreduktion von PCA deutlich schlechter als bei den restlichen Methoden ist. Dies ist wahrscheinlich der nichtlinearen Mannigfaltigkeit geschuldet, was der linearen Principal Component Analysis Schwierigkeiten bereitet. (Eigene Darstellung)}
	\label{fig:TwinPeaksMetrics}
\end{figure}

\begin{figure}[ht]
	\begin{center}
		\includegraphics{ICMR_comparison.pdf}
	\end{center}
	\caption[Qualitätskriterien für den ICMR-Datensatz]{Die Vertrauenswürdigkeit und Kontinuität der Dimensionsreduktion, sowie das Local Continuity Meta-Criterion (LCMC) für den ICMR-Datensatz. Dieser Datensatz ist kein Bilddatensatz, weswegen hier der Convolutional Autoencoder nicht eingesetzt werden konnte. Hier schneidet die Principal Component Analysis am besten ab, gefolgt von der Kernel PCA und vom vollvernetzten Autoencoder. Am schlechtesten sind der Contractive Autoencoder und Locally Linear Embedding, wobei die Qualitätskriterien mit größer werdender Nachbarschaftsgröße $K$ bei LLE deutlicher abfallen. (Eigene Darstellung)}
	\label{fig:ICMRMetrics}
\end{figure}

\begin{figure}[ht]
	\begin{center}
		\includegraphics{OlivettiFaces_comparison.pdf}
	\end{center}
	\caption[Qualitätskriterien für den ORL-Datensatz]{Die Vertrauenswürdigkeit und Kontinuität der Dimensionsreduktion, sowie das Local Continuity Meta-Criterion (LCMC) für den ORL Datensatz. Principal Component Analysis und die nichtlineare Erweiterung Kernel PCA sind auf diesem Datensatz fast identisch und liefern gleichzeitig die besten Ergebnisse auf allen drei Kriterien. Alle Varianten der Autoencoder fallen hier etwas in der Performance ab. Dies könnte an der geringen Stichprobengröße von 400 liegen, wodurch eine Konvergenz der Autoencoder schwieriger wird. Neben den Autoencoder schneidet hier auch LLE für größere Werte von $K$ schlecht ab, kann jedoch bei geringeren Nachbarschaftsgrößen noch gute Werte für die drei Kriterien erreichen. (Eigene Darstellung)}
	\label{fig:OlivettiFacesMetrics}
\end{figure}

\begin{figure}[ht]
	\begin{center}
		\includegraphics{FashionMNIST_comparison.pdf}
	\end{center}
	\caption[Qualitätskriterien für den Fashion MNIST-Datensatz]{Die Vertrauenswürdigkeit und Kontinuität der Dimensionsreduktion, sowie das Local Continuity Meta-Criterion (LCMC) für den Fashion MNIST-Datensatz. Die Kriterien auf diesem Datensatz zeigen ein ähnliches Bild wie auf dem Fashion MNIST-Datensatz, jedoch können die Principal Component Analysis, Kernel Principal Component Analysis und der Autoencoder etwas näher aufschließen. Alle Methoden bis auf Locally Linear Embedding und der Contractive Autoencoder können eine fast perfekte Vertrauenswürdigkeit und Kontinuität erreichen. Hinsichtlich des LCMC schneidet der Convolutional Autoencoder am besten ab, gefolgt vom vollvernetzten Autoencoder, sowie von PCA und Kernel PCA. (Eigene Darstellung)}
	\label{fig:FashionMNISTMetrics}
\end{figure}

\begin{figure}[ht]
	\begin{center}
		\includegraphics{FER2013_comparison.pdf}
	\end{center}
	\caption[Qualitätskriterien für den FER-Datensatz]{Die Vertrauenswürdigkeit und Kontinuität der Dimensionsreduktion, sowie das Local Continuity Meta-Criterion (LCMC) für den FER-Datensatz. Hier ist die Performance des Convolutional Autoencoders und des vollvernetzten Autoencoders nahezu identisch. Allerdings werden diese beiden Autoencoder durch die PCA und Kernel PCA hinsichtlich des LCMC outperformed. Die Vertrauenswürdigkeit und Kontinuität ist bei den vier Methoden nahezu perfekt. LLE und der Contractive Autoencoder schneiden auch auf diesem Datensatz mit Abstand am schlechtesten ab. Besonders LLE zeigt hier die Schwäche einer lokalen Erhaltung der Struktur, da die Qualitätskriterien für steigende Werte von $K$ stark abfallen. (Eigene Darstellung)}
	\label{fig:FER2013Metrics}
\end{figure}

% \section{Sonstige Abbildungen}

% \begin{figure}
% 	\centering
% 	\includegraphics{TwinPeaksEmbeddings.pdf}
% 	\caption[Latente zweidimensionale Repräsentationen $\mat{Y}$ durch Anwendungen fünf unterschiedlicher Methoden auf dem Twin Peaks-Datensatz.]{Abgebildet sind die latenten zweidimensionalen Repräsentationen $\mat{Y}$ durch Anwendungen fünf unterschiedlicher Methoden auf dem Twin Peaks-Datensatz. Die von Locally Linear Embedding gefundene latente Repräsentation hat die einzelnen Peaks herabsenken können. Kernel PCA konnte dies im Gegensatz zur linearen Principal Component Analysis ebenfalls erkennen. Auch die latente Repräsentation des vollvernetzten Autoencoders zeigt diesen Ansatz, verzerrt die Peaks in der Ebene jedoch stärker als es bei LLE oder Kernel PCA der Fall ist. Der Contractive Autoencoder scheint alle Punkte auf die Ränder abzubilden, was die niedrigere Vertrauenswürdigkeit und Kontinuität erklärt.}
% 	\label{fig:TwinPeaksEmbeddings}
% \end{figure}